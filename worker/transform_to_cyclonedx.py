import datetime
import json
import os
import sys
from cyclonedx.model.bom import Bom
from cyclonedx.model.component import Component, ComponentType
from cyclonedx.schema import OutputFormat, SchemaVersion
from cyclonedx.factory.license import LicenseFactory
from cyclonedx.model import HashType, XsUri, HashAlgorithm
from cyclonedx.model.contact import OrganizationalEntity
from cyclonedx.model import Property
from cyclonedx.output.json import JsonV1Dot5, JsonV1Dot6
from cyclonedx.validation.json import JsonStrictValidator
from cyclonedx.exception import MissingOptionalDependencyException

import uuid

lc_factory = LicenseFactory()

def transform_to_cyclonedx(bom_data):
    """
    Transform the given BOM data into a CycloneDX format.
    Args:
        bom_data (dict): The BOM data to transform.
    Returns:
        Bom: A CycloneDX formatted BOM instance.
    """
    
    print("TEST / Transforming BOM data to CycloneDX format...")
    print(json.dumps(bom_data, indent=4))
    
    # Create a new BOM instance
    bom = Bom()
    bom.version = 1
    
    # BOM: metadata =========================================================================================================
    bom.metadata.timestamp = datetime.datetime.now()
    # BOM: metadata: tools (AIBoMGen)
    bom.metadata.tools.components.add(
        Component(
            name="AIBoMGen",
            version="0.1.0",
            type=ComponentType.PLATFORM,
            supplier=OrganizationalEntity(
                name="Ghent University",
                urls=[XsUri('https://www.ugent.be/')]
            ),
            group="Ghent University",
            licenses=[lc_factory.make_from_string('MIT')],
        )
    )
    # BOM: metadata: authors
    bom.metadata.authors = "BOM generated by AIBoMGen"
    # BOM: metadata: supplier and manufacturer
    bom.metadata.supplier = "Ghent University"
    bom.metadata.manufacturer = "Ghent University"
    # BOM: metadata: licenses (optional listing of different licenses from components (may be deleted later))
    bom.metadata.licenses = [lc_factory.make_from_string(bom_data.get("license", "Unknown"))]
    # BOM: components: add components to the BOM =============================================================================
    
        # ...
        
    # BOM: components: add final model to the BOM   ----------------------------------------------------------------------
    model_component = Component(
        type=ComponentType.MACHINE_LEARNING_MODEL,
        name=bom_data.get("model_name", "Unknown Model"),
        version=bom_data.get("model_version", "Unknown Version"),
        description=bom_data.get("model_description", "Description of the AI model"),
        licenses=[lc_factory.make_from_string(bom_data.get("license", "Unknown"))],
        properties=[
            Property(name="Framework", value=bom_data.get("framework", "Unknown")),
            Property(name="Model Type", value=bom_data.get("model_type", "Unknown")),
            Property(name="Base Model", value=bom_data.get("base_model", "Unknown")),
            Property(name="Base Model Source", value=bom_data.get("base_model_source", "Unknown")),
            Property(name="Intended Use", value=bom_data.get("intended_use", "Unknown")),
            Property(name="Out of Scope", value=bom_data.get("out_of_scope", "Unknown")),
            Property(name="Misuse or Malicious Use", value=bom_data.get("misuse_or_malicious", "Unknown")),
        ]
        # modelCard NOT SUPPORTED YET IN CYCLONEDX PYTHON LIBRARY
        # for the moment add them as custom properties
    )
    # TODO: add model card as a CycloneDX model card (if supported in the future)
    # Add modelCard as a custom property
    # model_card = bom_data.get("model_card", {})
    # if model_card:
    #     model_card_json = json.dumps(model_card, indent=2)
    #     model_component.properties.append({"name": "modelCard", "value": model_card_json})

    # Add the model component to the BOM
    bom.components.add(model_component)
    
                
    
    # BOM: components: add datasets to the BOM ---------------------------------------------------------------------------
    # TODO: use dataset definition file to enhance the dataset information
    for dataset_name, dataset_info in bom_data.get("datasets", {}).items():
        bom.components.add(
            Component(
                type=ComponentType.DATA,
                name=dataset_name,
                version=dataset_info.get("version", "Unknown"),
                description=dataset_info.get("description", "Dataset used for training"),
                properties=[
                    Property(name="Source", value=dataset_info.get("source", "Unknown")),
                    Property(name="License", value=dataset_info.get("license", "Unknown")),
                    Property(name="Definition", value=dataset_info.get("definition", "Unknown")),
                ]
            )
        )
        
    # BOM: components: add input artifacts
    for artifact_name, artifact_info in bom_data.get("input_artifacts", {}).items():
        artifact_hash = HashType(alg=HashAlgorithm("SHA-256"), content=artifact_info.get("hash", "unknown"))
        bom.components.add(
            Component(
                type=ComponentType.FILE,
                name=artifact_name,
                version="1.0",
                description=artifact_info.get("description", "Input artifact"),
                hashes=[artifact_hash],
                properties=[
                    Property(name="Path", value=artifact_info.get("path", "Unknown")),
                ]
            )
        )

    # BOM: components: add output artifacts
    for artifact_name, artifact_info in bom_data.get("output_artifacts", {}).items():
        artifact_hash = HashType(alg=HashAlgorithm("SHA-256"), content=artifact_info.get("hash", "unknown"))
        bom.components.add(
            Component(
                type=ComponentType.FILE,
                name=artifact_name,
                version="1.0",
                description=artifact_info.get("description", "Output artifact"),
                hashes=[artifact_hash],
                properties=[
                    Property(name="Path", value=artifact_info.get("path", "Unknown")),
                ]
            )
        )
        
    # BOM: components: add container environment for training to the BOM --------------------------------------------------
    
    training_environment = bom_data.get("training_environment", {})
    if training_environment:
        environment_component = Component(
            type=ComponentType.CONTAINER,
            name="AIBOMGen Training Environment",
            description="The environment used for training the AI model",
            properties=[
                Property(name="Operating System", value=training_environment.get("os", "Unknown")),
                Property(name="Python Version", value=training_environment.get("python_version", "Unknown")),
                Property(name="TensorFlow Version", value=training_environment.get("tensorflow_version", "Unknown")),
                Property(name="Request Time", value=training_environment.get("request_time", "Unknown")),
                Property(name="Start Training Time", value=training_environment.get("start_training_time", "Unknown")),
                Property(name="Start AIBoM Time", value=training_environment.get("start_aibom_time", "Unknown")),
                Property(name="Training Time (seconds)", value=str(training_environment.get("training_time", "Unknown"))),
                Property(name="Job ID", value=training_environment.get("job_id", "Unknown")),
                Property(name="Unique Directory", value=training_environment.get("unique_dir", "Unknown")),
            ]
        )
        bom.components.add(environment_component)
        
    
    
    
    # BOM: services: add services to the BOM
    
        # ...
    
    # BOM: external references: add external references to the BOM
        # (e.g., links to the original model, datasets, etc.)
    
        # ...
    
    # BOM: vulnerabilites: add vulnerabilities to the BOM
    
        # ...
    
    # BOM: dependencies: add dependencies to the BOM
    
        # link different components together (e.g., model -> dataset, model -> service)
        # ...
    
    # BOM: definitions: add definitions to the BOM
    
        # ...
    
    # BOM: get_urn_uuid() -> str get the UUID of the BOM
    # BOM: has_component(component: Component) -> Check whether this Bom contains the provided Component
    # BOM: get_vulnerabilities_for_bom_ref(bom_ref: BomRef) -> SortedSet[Vulnerability] | None
    # BOM: has_vulnerabilities() -> bool
    # BOM: urn() -> str
    # BOM: validate() -> bool
    
    return bom
    
def serialize_bom(bom, output_path, schema_version=SchemaVersion.V1_6):
    """
    Serialize the BOM to a file in JSON format and validate it.
    Args:
        bom (Bom): The CycloneDX BOM instance.
        output_path (str): The file path to save the serialized BOM.
        schema_version (SchemaVersion): The CycloneDX schema version to use.
    """
    # Generate JSON output
    try:
        json_outputter = JsonV1Dot6(bom)
        serialized_json = json_outputter.output_as_string(indent=4)

        # Manually format the output using json.dumps() to pretty print it
        pretty_json = json.dumps(json.loads(serialized_json), indent=4)

        # Validation
        json_validator = JsonStrictValidator(schema_version)
        try:
            validation_errors = json_validator.validate_str(pretty_json)
            if validation_errors:
                print("JSON invalid", "ValidationError:", repr(validation_errors), sep="\n", file=sys.stderr)
                sys.exit(2)
            print("JSON valid")
        except MissingOptionalDependencyException as error:
            print("JSON validation was skipped due to", error)

        # Write the JSON output to the file
        try:
            with open(output_path, "w") as file:
                file.write(pretty_json)
        except FileExistsError:
            print(f"File {output_path} already exists, overwriting...")
            os.remove(output_path)  # Remove existing file before writing new one
            with open(output_path, "w") as file:
                file.write(pretty_json)
        finally:
            print(f"Final AIBoM generated at {output_path}")

    except MissingOptionalDependencyException as error:
        print(f"Serialization failed due to missing optional dependency: {error}")
